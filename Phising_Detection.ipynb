{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "QJmpyFMwkKHj"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the data\n",
        "df = pd.read_csv(\"shuffled_combined_dataset.csv\")\n",
        "\n"
      ],
      "metadata": {
        "id": "nsCNcRqmk6Ns"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert URLs to character level encoding and pad to length of 200\n",
        "tokenizer = Tokenizer(char_level=True)\n",
        "tokenizer.fit_on_texts(df['urls'])\n",
        "encoded_urls = tokenizer.texts_to_sequences(df['urls'])\n",
        "padded_urls = pad_sequences(encoded_urls, maxlen=200)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "HRYfqB8Kk6QO"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(padded_urls, df['type'], test_size=0.2, random_state=42)\n",
        "\n"
      ],
      "metadata": {
        "id": "zNvY6SN-k6SN"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the CNN model\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=32, input_length=200))\n",
        "model.add(Conv1D(128, 5, activation='relu'))\n",
        "model.add(MaxPooling1D(5))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Encode the labels to numerical values\n",
        "label_encoder = LabelEncoder()\n",
        "y_train_encoded = label_encoder.fit_transform(y_train)\n",
        "y_test_encoded = label_encoder.transform(y_test)\n",
        "print(label_encoder.classes_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ap2Rd9J7k6Vp",
        "outputId": "2bf7ee47-7cf1-46bf-b2fc-77af771deeed"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Phish' 'safe']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the CNN model with encoded labels\n",
        "model.fit(X_train, y_train_encoded, epochs=10, batch_size=32, validation_split=0.2)\n",
        "\n",
        "# Extract features from the CNN model\n",
        "feature_extractor = Sequential(model.layers[:-2])  # Exclude the last Dense and Dropout layers\n",
        "X_train_features = feature_extractor.predict(X_train)\n",
        "X_test_features = feature_extractor.predict(X_test)\n",
        "\n",
        "# Train a Random Forest classifier\n",
        "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_classifier.fit(X_train_features, y_train)\n",
        "\n",
        "# Predict using the RF classifier\n",
        "y_pred = rf_classifier.predict(X_test_features)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "prxMtOGswrGt",
        "outputId": "4ff79d34-98a6-4cfb-e766-7049dd7c8ee3"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "600/600 [==============================] - 16s 10ms/step - loss: 5.2176 - accuracy: 0.2790 - val_loss: 2.7396 - val_accuracy: 0.3421\n",
            "Epoch 2/10\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 5.1499 - accuracy: 0.4097 - val_loss: 2.7732 - val_accuracy: 0.4156\n",
            "Epoch 3/10\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 5.1495 - accuracy: 0.4045 - val_loss: 2.7765 - val_accuracy: 0.3927\n",
            "Epoch 4/10\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 5.1228 - accuracy: 0.4049 - val_loss: 2.7046 - val_accuracy: 0.4273\n",
            "Epoch 5/10\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 5.0972 - accuracy: 0.4293 - val_loss: 2.6704 - val_accuracy: 0.4467\n",
            "Epoch 6/10\n",
            "600/600 [==============================] - 3s 6ms/step - loss: 5.0472 - accuracy: 0.4167 - val_loss: 2.5121 - val_accuracy: 0.4267\n",
            "Epoch 7/10\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 5.0063 - accuracy: 0.4383 - val_loss: 2.4758 - val_accuracy: 0.4231\n",
            "Epoch 8/10\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 4.9890 - accuracy: 0.4370 - val_loss: 2.4120 - val_accuracy: 0.4417\n",
            "Epoch 9/10\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 4.9721 - accuracy: 0.4645 - val_loss: 2.4691 - val_accuracy: 0.4692\n",
            "Epoch 10/10\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 4.9712 - accuracy: 0.4679 - val_loss: 2.3822 - val_accuracy: 0.4654\n",
            "750/750 [==============================] - 1s 1ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "Accuracy: 0.99\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming your single URL is stored in a variable named single_url\n",
        "\n",
        "# 1. Preprocess the URL\n",
        "encoded_single_url = tokenizer.texts_to_sequences([\"\thttp://qw.nelidacoassssio.repl.co/\"])\n",
        "padded_single_url = pad_sequences(encoded_single_url, maxlen=200)\n",
        "\n",
        "# 2. Feature Extraction with CNN\n",
        "single_url_features = feature_extractor.predict(padded_single_url)\n",
        "\n",
        "# 3. Prediction with Random Forest\n",
        "predicted_label = rf_classifier.predict(single_url_features)[0]\n",
        "print(predicted_label)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AdOQ0PLHwrJN",
        "outputId": "131b5fb7-7b9b-4fbc-ace1-ad743ba9656d"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 31ms/step\n",
            "Phish\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 1. Save the CNN model\n",
        "cnn_model_path = \"cnn_model.h5\"\n",
        "model.save(cnn_model_path)\n",
        "\n",
        "# 2. Save the Random Forest model\n",
        "import joblib\n",
        "\n",
        "rf_model_path = \"rf_model.pkl\"\n",
        "joblib.dump(rf_classifier, rf_model_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RRKesatywrLq",
        "outputId": "574b4532-4e3c-4449-ff1c-d2f0be6811fb"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['rf_model.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Load the CNN model from the saved file\n",
        "cnn_model = load_model(\"cnn_model.h5\")\n"
      ],
      "metadata": {
        "id": "FFqtYZTfwrOe"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "# Load the Random Forest model from the saved file\n",
        "rf_classifier = joblib.load(\"rf_model.pkl\")\n"
      ],
      "metadata": {
        "id": "SfKz3gbf2LPS"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_url(single_url):\n",
        "    # Preprocess the URL\n",
        "    encoded_single_url = tokenizer.texts_to_sequences([single_url])\n",
        "    padded_single_url = pad_sequences(encoded_single_url, maxlen=200)\n",
        "\n",
        "    # Extract features using the feature_extractor from the CNN model\n",
        "    url_features = feature_extractor.predict(padded_single_url)\n",
        "\n",
        "    # Predict using the Random Forest model\n",
        "    predicted_label = rf_classifier.predict(url_features)[0]\n",
        "\n",
        "    return predicted_label\n",
        "\n",
        "# Example\n",
        "url_to_predict = \"https://www.google.com\"\n",
        "print(predict_url(url_to_predict))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lUq1ijFc2LR0",
        "outputId": "44b94266-c604-4789-d177-3ab1d7c07242"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 22ms/step\n",
            "safe\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bwf4kIkM2LUH"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hJnjYppn2LWk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uQt4Lhe42LY4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}